{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ссылка на Колаб\n",
    "\n",
    "https://colab.research.google.com/drive/1zahApPVCu0_9fz9yuiL2L1g-rnFdwv6s#scrollTo=O3U8vKNP72T7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "покажи Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN в картинках от \"Системного блока\".\n",
    "\n",
    "https://sysblok.ru/knowhow/mama-myla-lstm-kak-ustroeny-rekurrentnye-nejroseti-s-dolgoj-kratkosrochnoj-pamjatju/\n",
    "\n",
    "https://sysblok.ru/knowhow/vnimanie-vse-chto-vam-nuzhno-kak-rabotaet-attention-v-nejrosetjah/\n",
    "\n",
    "https://sysblok.ru/knowhow/kak-rabotajut-transformery-krutejshie-nejroseti-nashih-dnej/\n",
    "\n",
    "Внимание, ИТМО\n",
    "\n",
    "https://neerc.ifmo.ru/wiki/index.php?title=%D0%9C%D0%B5%D1%85%D0%B0%D0%BD%D0%B8%D0%B7%D0%BC_%D0%B2%D0%BD%D0%B8%D0%BC%D0%B0%D0%BD%D0%B8%D1%8F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Функции активации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основные неплохо рассмотрены [здесь](https://neurohive.io/ru/osnovy-data-science/activation-functions/).\n",
    "\n",
    "Полный список [здесь](https://ru.wikipedia.org/wiki/%D0%A4%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D1%8F_%D0%B0%D0%BA%D1%82%D0%B8%D0%B2%D0%B0%D1%86%D0%B8%D0%B8)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Функции потерь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 1. (R)MSE ((Root) Mean Squared Error)\n",
    "\n",
    "$$ L(\\hat{y}, y) = \\frac{1}{N}\\sum\\limits_n^N (y_n - \\hat{y}_n)^2$$\n",
    "\n",
    "#### 2. MAE (Mean Absolute Error)\n",
    "\n",
    "$$ L(\\hat{y}, y) = \\frac{1}{N}\\sum\\limits_n^N |y_n - \\hat{y}_n|$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. RSE (Relative Squared Error)**\n",
    "\n",
    "$$ L(\\hat{y}, y) = \\sqrt\\frac{\\sum\\limits_n^N (y_n - \\hat{y}_n)^2}{\\sum\\limits_n^N (y_n - \\bar{y})^2}$$\n",
    "\n",
    "**4. RAE (Relative Absolute Error)**\n",
    "\n",
    "$$ L(\\hat{y}, y) = \\frac{\\sum\\limits_n^N |y_n - \\hat{y}_n|}{\\sum\\limits_n^N |y_n - \\bar{y}|}$$\n",
    "\n",
    "**5. MAPE (Mean Absolute Persentage Error)**\n",
    "\n",
    "$$ L(\\hat{y}, y) = \\frac{100}{N} \\sum\\limits_n^N\\left|\\frac{ y_n - \\hat{y}_n}{y_n}\\right|$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. RMSLE (Root Mean Squared Logarithmic Error)**\n",
    "\n",
    "$$ L(\\hat{y}, y) = \\sqrt{\\frac{1}{N}\\sum\\limits_n^N(\\log(y_n + 1) - \\log(\\hat{y}_n + 1))^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Искусственные нейронные сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считываем набор данных цифр MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = digits.images\n",
    "plt.imshow(img[1], cmap=plt.cm.Greys_r);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = img.reshape(-1, 64)\n",
    "y = digits.target\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.2)\n",
    "test_y = test_y.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Персептрон из библиотеки [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html?highlight=mlpclassifier#sklearn.neural_network.MLPClassifier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier((128, 64), activation='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 8, 2, ..., 8, 3, 6])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(128, 64))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(128, 64))</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(128, 64))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 4, 5, 5, 2, 2, 6, 0, 6, 9, 5, 4, 0, 8, 6, 1, 1, 6, 4, 8, 2, 6,\n",
       "       3, 8, 0, 8, 7, 0, 9, 1, 0, 5, 5, 5, 3, 8, 4, 0, 2, 7, 8, 4, 3, 4,\n",
       "       2, 9, 7, 3, 0, 5, 7, 9, 9, 8, 3, 6, 1, 1, 1, 7, 9, 7, 9, 9, 3, 1,\n",
       "       1, 2, 2, 0, 5, 6, 2, 1, 3, 8, 8, 3, 1, 3, 7, 8, 4, 2, 0, 1, 3, 7,\n",
       "       5, 0, 7, 3, 5, 5, 6, 0, 8, 3, 3, 9, 0, 5, 7, 7, 9, 1, 8, 2, 2, 3,\n",
       "       7, 6, 0, 1, 3, 8, 4, 1, 6, 4, 9, 6, 0, 9, 6, 3, 1, 9, 4, 6, 7, 4,\n",
       "       7, 1, 0, 3, 6, 9, 6, 6, 2, 0, 9, 0, 6, 8, 8, 6, 5, 2, 7, 8, 5, 4,\n",
       "       3, 3, 3, 4, 5, 8, 5, 5, 3, 9, 7, 2, 3, 6, 1, 5, 5, 5, 8, 4, 7, 9,\n",
       "       4, 1, 9, 1, 7, 3, 4, 5, 2, 1, 4, 8, 6, 2, 5, 2, 9, 5, 0, 2, 2, 9,\n",
       "       5, 8, 5, 5, 7, 7, 3, 5, 2, 3, 2, 9, 7, 2, 2, 0, 9, 4, 1, 3, 3, 0,\n",
       "       1, 3, 5, 6, 1, 1, 8, 9, 6, 9, 4, 0, 6, 5, 6, 4, 0, 4, 7, 4, 0, 3,\n",
       "       3, 4, 4, 0, 4, 0, 5, 9, 9, 1, 9, 9, 6, 1, 0, 0, 9, 1, 8, 0, 3, 8,\n",
       "       2, 6, 2, 1, 5, 4, 5, 1, 1, 5, 1, 9, 2, 4, 5, 2, 2, 8, 4, 2, 5, 1,\n",
       "       1, 5, 7, 8, 1, 7, 2, 7, 3, 5, 6, 3, 6, 9, 1, 0, 6, 5, 2, 9, 3, 8,\n",
       "       5, 1, 4, 8, 9, 5, 8, 9, 4, 4, 4, 6, 9, 3, 7, 5, 0, 2, 2, 0, 3, 8,\n",
       "       6, 5, 4, 2, 2, 9, 1, 0, 6, 0, 5, 2, 0, 3, 3, 8, 6, 0, 1, 2, 0, 8,\n",
       "       4, 3, 9, 9, 2, 9, 7, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[36,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 36,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0, 38,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 39,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0, 34,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 42,  0,  0,  0,  1],\n",
       "       [ 0,  1,  0,  0,  0,  0, 34,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 27,  0,  1],\n",
       "       [ 1,  1,  0,  0,  0,  0,  0,  0, 30,  0],\n",
       "       [ 0,  0,  0,  0,  0,  1,  0,  0,  1, 37]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_y.reshape(-1), y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.97297297, 0.94736842, 1.        , 1.        , 1.        ,\n",
       "        0.97674419, 1.        , 1.        , 0.96774194, 0.94871795]),\n",
       " array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.97674419, 0.97142857, 0.96428571, 0.9375    , 0.94871795]),\n",
       " array([0.98630137, 0.97297297, 1.        , 1.        , 1.        ,\n",
       "        0.97674419, 0.98550725, 0.98181818, 0.95238095, 0.94871795]),\n",
       " array([36, 36, 38, 39, 34, 43, 35, 28, 32, 39]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(test_y.reshape(-1), y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9805555555555555"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_y.reshape(-1), y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('perceptron.pickle', 'wb') as out_file:\n",
    "    pickle.dump(model, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('perceptron.pickle', 'rb') as out_file:\n",
    "    model2 = pickle.load(out_file)\n",
    "y_hat2 = model2.predict(test_x)\n",
    "accuracy_score(test_y.reshape(-1), y_hat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_backprop',\n",
       " '_check_feature_names',\n",
       " '_check_n_features',\n",
       " '_check_solver',\n",
       " '_compute_loss_grad',\n",
       " '_estimator_type',\n",
       " '_fit',\n",
       " '_fit_lbfgs',\n",
       " '_fit_stochastic',\n",
       " '_forward_pass',\n",
       " '_forward_pass_fast',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_init_coef',\n",
       " '_initialize',\n",
       " '_label_binarizer',\n",
       " '_loss_grad_lbfgs',\n",
       " '_more_tags',\n",
       " '_no_improvement_count',\n",
       " '_optimizer',\n",
       " '_random_state',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_unpack',\n",
       " '_update_no_improvement_count',\n",
       " '_validate_data',\n",
       " '_validate_hyperparameters',\n",
       " '_validate_input',\n",
       " 'activation',\n",
       " 'alpha',\n",
       " 'batch_size',\n",
       " 'best_loss_',\n",
       " 'beta_1',\n",
       " 'beta_2',\n",
       " 'classes_',\n",
       " 'coefs_',\n",
       " 'early_stopping',\n",
       " 'epsilon',\n",
       " 'fit',\n",
       " 'get_params',\n",
       " 'hidden_layer_sizes',\n",
       " 'intercepts_',\n",
       " 'learning_rate',\n",
       " 'learning_rate_init',\n",
       " 'loss',\n",
       " 'loss_',\n",
       " 'loss_curve_',\n",
       " 'max_fun',\n",
       " 'max_iter',\n",
       " 'momentum',\n",
       " 'n_features_in_',\n",
       " 'n_iter_',\n",
       " 'n_iter_no_change',\n",
       " 'n_layers_',\n",
       " 'n_outputs_',\n",
       " 'nesterovs_momentum',\n",
       " 'out_activation_',\n",
       " 'partial_fit',\n",
       " 'power_t',\n",
       " 'predict',\n",
       " 'predict_log_proba',\n",
       " 'predict_proba',\n",
       " 'random_state',\n",
       " 'score',\n",
       " 'set_params',\n",
       " 'shuffle',\n",
       " 'solver',\n",
       " 't_',\n",
       " 'tol',\n",
       " 'validation_fraction',\n",
       " 'verbose',\n",
       " 'warm_start']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.coefs_), len(model.coefs_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00247475, -0.09960008, -0.04939996, -0.17113874, -0.04233107,\n",
       "        -0.02774523,  0.01265585,  0.08418831],\n",
       "       [ 0.11408602, -0.20398952,  0.07801585,  0.09784062,  0.07054136,\n",
       "         0.00712292,  0.10877999, -0.04331388],\n",
       "       [ 0.01414501,  0.09529548,  0.05160871, -0.1004476 ,  0.14782788,\n",
       "         0.12759275,  0.00190022, -0.09064424],\n",
       "       [ 0.2282467 , -0.07512824, -0.12568085,  0.0115262 , -0.1021823 ,\n",
       "        -0.15235423,  0.07675557, -0.11610491],\n",
       "       [ 0.00135536, -0.05209357,  0.1097189 ,  0.06854361, -0.04546797,\n",
       "         0.15677218, -0.03520863, -0.00137092],\n",
       "       [-0.11478447, -0.11921545,  0.17713993,  0.08509785, -0.10597628,\n",
       "         0.13971005,  0.12493481, -0.12950809],\n",
       "       [ 0.02724119, -0.15338656, -0.06942815, -0.02398183,  0.07938802,\n",
       "        -0.1230603 ,  0.08988193,  0.06857435],\n",
       "       [-0.0896196 ,  0.1093499 ,  0.10584174,  0.13900292,  0.05143504,\n",
       "        -0.07945885, -0.17260393,  0.02516545]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coefs_[0][:, 10].reshape((8, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(model.coefs_[0][:, 10].reshape((8, -1)), cmap=plt.cm.Greys_r);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'loss_curve_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5996/1215016814.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_curve_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'loss_curve_'"
     ]
    }
   ],
   "source": [
    "model.loss_curve_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем сверточные и рекуррентные сети из Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-09 16:23:35.824438: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-09 16:23:35.847185: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хорошо, сперва полносвязанная сеть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(128, activation=\"tanh\", kernel_regularizer=keras.regularizers.l2(0.001), input_shape=(64,)))\n",
    "model.add(layers.Dense(128, activation=\"tanh\", kernel_regularizer=keras.regularizers.l2(0.001)))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "model.compile(keras.optimizers.SGD(learning_rate=0.001), \n",
    "          keras.losses.MeanSquaredError(reduction='sum'),\n",
    "          metrics=['accuracy']\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y2 = []\n",
    "for y in train_y:\n",
    "    y2 = np.zeros(10)\n",
    "    y2[y] = 1\n",
    "    train_y2.append(y2)\n",
    "    \n",
    "test_y2 = []\n",
    "for y in test_y:\n",
    "    y2 = np.zeros(10)\n",
    "    y2[y] = 1\n",
    "    test_y2.append(y2)\n",
    "    \n",
    "train_y2 = np.array(train_y2)\n",
    "test_y2 = np.array(test_y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "288/288 [==============================] - 0s 686us/step - loss: 0.6889 - accuracy: 0.0919\n",
      "Epoch 2/200\n",
      "288/288 [==============================] - 0s 677us/step - loss: 0.6688 - accuracy: 0.1461\n",
      "Epoch 3/200\n",
      "288/288 [==============================] - 0s 656us/step - loss: 0.6473 - accuracy: 0.2575\n",
      "Epoch 4/200\n",
      "288/288 [==============================] - 0s 664us/step - loss: 0.6256 - accuracy: 0.3424\n",
      "Epoch 5/200\n",
      "288/288 [==============================] - 0s 682us/step - loss: 0.6046 - accuracy: 0.3911\n",
      "Epoch 6/200\n",
      "288/288 [==============================] - 0s 652us/step - loss: 0.5848 - accuracy: 0.4280\n",
      "Epoch 7/200\n",
      "288/288 [==============================] - 0s 649us/step - loss: 0.5664 - accuracy: 0.4516\n",
      "Epoch 8/200\n",
      "288/288 [==============================] - 0s 645us/step - loss: 0.5495 - accuracy: 0.4920\n",
      "Epoch 9/200\n",
      "288/288 [==============================] - 0s 650us/step - loss: 0.5337 - accuracy: 0.5539\n",
      "Epoch 10/200\n",
      "288/288 [==============================] - 0s 636us/step - loss: 0.5185 - accuracy: 0.5908\n",
      "Epoch 11/200\n",
      "288/288 [==============================] - 0s 650us/step - loss: 0.5040 - accuracy: 0.6207\n",
      "Epoch 12/200\n",
      "288/288 [==============================] - 0s 689us/step - loss: 0.4902 - accuracy: 0.6653\n",
      "Epoch 13/200\n",
      "288/288 [==============================] - 0s 693us/step - loss: 0.4765 - accuracy: 0.6889\n",
      "Epoch 14/200\n",
      "288/288 [==============================] - 0s 699us/step - loss: 0.4633 - accuracy: 0.7112\n",
      "Epoch 15/200\n",
      "288/288 [==============================] - 0s 687us/step - loss: 0.4508 - accuracy: 0.7356\n",
      "Epoch 16/200\n",
      "288/288 [==============================] - 0s 666us/step - loss: 0.4389 - accuracy: 0.7564\n",
      "Epoch 17/200\n",
      "288/288 [==============================] - 0s 646us/step - loss: 0.4273 - accuracy: 0.7731\n",
      "Epoch 18/200\n",
      "288/288 [==============================] - 0s 651us/step - loss: 0.4164 - accuracy: 0.7878\n",
      "Epoch 19/200\n",
      "288/288 [==============================] - 0s 656us/step - loss: 0.4058 - accuracy: 0.8045\n",
      "Epoch 20/200\n",
      "288/288 [==============================] - 0s 649us/step - loss: 0.3958 - accuracy: 0.8128\n",
      "Epoch 21/200\n",
      "288/288 [==============================] - 0s 677us/step - loss: 0.3859 - accuracy: 0.8274\n",
      "Epoch 22/200\n",
      "288/288 [==============================] - 0s 689us/step - loss: 0.3762 - accuracy: 0.8455\n",
      "Epoch 23/200\n",
      "288/288 [==============================] - 0s 669us/step - loss: 0.3665 - accuracy: 0.8657\n",
      "Epoch 24/200\n",
      "288/288 [==============================] - 0s 653us/step - loss: 0.3573 - accuracy: 0.8796\n",
      "Epoch 25/200\n",
      "288/288 [==============================] - 0s 653us/step - loss: 0.3485 - accuracy: 0.8887\n",
      "Epoch 26/200\n",
      "288/288 [==============================] - 0s 654us/step - loss: 0.3404 - accuracy: 0.8956\n",
      "Epoch 27/200\n",
      "288/288 [==============================] - 0s 662us/step - loss: 0.3332 - accuracy: 0.9033\n",
      "Epoch 28/200\n",
      "288/288 [==============================] - 0s 645us/step - loss: 0.3264 - accuracy: 0.9068\n",
      "Epoch 29/200\n",
      "288/288 [==============================] - 0s 657us/step - loss: 0.3203 - accuracy: 0.9130\n",
      "Epoch 30/200\n",
      "288/288 [==============================] - 0s 655us/step - loss: 0.3149 - accuracy: 0.9193\n",
      "Epoch 31/200\n",
      "288/288 [==============================] - 0s 698us/step - loss: 0.3098 - accuracy: 0.9241\n",
      "Epoch 32/200\n",
      "288/288 [==============================] - 0s 679us/step - loss: 0.3052 - accuracy: 0.9290\n",
      "Epoch 33/200\n",
      "288/288 [==============================] - 0s 678us/step - loss: 0.3008 - accuracy: 0.9311\n",
      "Epoch 34/200\n",
      "288/288 [==============================] - 0s 649us/step - loss: 0.2972 - accuracy: 0.9297\n",
      "Epoch 35/200\n",
      "288/288 [==============================] - 0s 655us/step - loss: 0.2934 - accuracy: 0.9318\n",
      "Epoch 36/200\n",
      "288/288 [==============================] - 0s 676us/step - loss: 0.2900 - accuracy: 0.9325\n",
      "Epoch 37/200\n",
      "288/288 [==============================] - 0s 693us/step - loss: 0.2870 - accuracy: 0.9360\n",
      "Epoch 38/200\n",
      "288/288 [==============================] - 0s 693us/step - loss: 0.2840 - accuracy: 0.9367\n",
      "Epoch 39/200\n",
      "288/288 [==============================] - 0s 700us/step - loss: 0.2814 - accuracy: 0.9381\n",
      "Epoch 40/200\n",
      "288/288 [==============================] - 0s 700us/step - loss: 0.2788 - accuracy: 0.9408\n",
      "Epoch 41/200\n",
      "288/288 [==============================] - 0s 685us/step - loss: 0.2763 - accuracy: 0.9422\n",
      "Epoch 42/200\n",
      "288/288 [==============================] - 0s 686us/step - loss: 0.2740 - accuracy: 0.9388\n",
      "Epoch 43/200\n",
      "288/288 [==============================] - 0s 668us/step - loss: 0.2718 - accuracy: 0.9457\n",
      "Epoch 44/200\n",
      "288/288 [==============================] - 0s 713us/step - loss: 0.2698 - accuracy: 0.9485\n",
      "Epoch 45/200\n",
      "288/288 [==============================] - 0s 688us/step - loss: 0.2679 - accuracy: 0.9492\n",
      "Epoch 46/200\n",
      "288/288 [==============================] - 0s 659us/step - loss: 0.2660 - accuracy: 0.9492\n",
      "Epoch 47/200\n",
      "288/288 [==============================] - 0s 650us/step - loss: 0.2640 - accuracy: 0.9520\n",
      "Epoch 48/200\n",
      "288/288 [==============================] - 0s 679us/step - loss: 0.2625 - accuracy: 0.9534\n",
      "Epoch 49/200\n",
      "288/288 [==============================] - 0s 714us/step - loss: 0.2606 - accuracy: 0.9541\n",
      "Epoch 50/200\n",
      "288/288 [==============================] - 0s 708us/step - loss: 0.2593 - accuracy: 0.9548\n",
      "Epoch 51/200\n",
      "288/288 [==============================] - 0s 730us/step - loss: 0.2576 - accuracy: 0.9562\n",
      "Epoch 52/200\n",
      "288/288 [==============================] - 0s 737us/step - loss: 0.2563 - accuracy: 0.9569\n",
      "Epoch 53/200\n",
      "288/288 [==============================] - 0s 665us/step - loss: 0.2549 - accuracy: 0.9582\n",
      "Epoch 54/200\n",
      "288/288 [==============================] - 0s 671us/step - loss: 0.2534 - accuracy: 0.9596\n",
      "Epoch 55/200\n",
      "288/288 [==============================] - 0s 724us/step - loss: 0.2522 - accuracy: 0.9610\n",
      "Epoch 56/200\n",
      "288/288 [==============================] - 0s 694us/step - loss: 0.2509 - accuracy: 0.9624\n",
      "Epoch 57/200\n",
      "288/288 [==============================] - 0s 672us/step - loss: 0.2497 - accuracy: 0.9631\n",
      "Epoch 58/200\n",
      "288/288 [==============================] - 0s 697us/step - loss: 0.2485 - accuracy: 0.9645\n",
      "Epoch 59/200\n",
      "288/288 [==============================] - 0s 695us/step - loss: 0.2473 - accuracy: 0.9652\n",
      "Epoch 60/200\n",
      "288/288 [==============================] - 0s 668us/step - loss: 0.2462 - accuracy: 0.9680\n",
      "Epoch 61/200\n",
      "288/288 [==============================] - 0s 659us/step - loss: 0.2451 - accuracy: 0.9680\n",
      "Epoch 62/200\n",
      "288/288 [==============================] - 0s 651us/step - loss: 0.2441 - accuracy: 0.9701\n",
      "Epoch 63/200\n",
      "288/288 [==============================] - 0s 663us/step - loss: 0.2430 - accuracy: 0.9722\n",
      "Epoch 64/200\n",
      "288/288 [==============================] - 0s 674us/step - loss: 0.2421 - accuracy: 0.9743\n",
      "Epoch 65/200\n",
      "288/288 [==============================] - 0s 653us/step - loss: 0.2411 - accuracy: 0.9743\n",
      "Epoch 66/200\n",
      "288/288 [==============================] - 0s 674us/step - loss: 0.2401 - accuracy: 0.9743\n",
      "Epoch 67/200\n",
      "288/288 [==============================] - 0s 668us/step - loss: 0.2392 - accuracy: 0.9756\n",
      "Epoch 68/200\n",
      "288/288 [==============================] - 0s 662us/step - loss: 0.2383 - accuracy: 0.9749\n",
      "Epoch 69/200\n",
      "288/288 [==============================] - 0s 660us/step - loss: 0.2375 - accuracy: 0.9756\n",
      "Epoch 70/200\n",
      "288/288 [==============================] - 0s 659us/step - loss: 0.2366 - accuracy: 0.9763\n",
      "Epoch 71/200\n",
      "288/288 [==============================] - 0s 656us/step - loss: 0.2358 - accuracy: 0.9784\n",
      "Epoch 72/200\n",
      "288/288 [==============================] - 0s 652us/step - loss: 0.2349 - accuracy: 0.9784\n",
      "Epoch 73/200\n",
      "288/288 [==============================] - 0s 656us/step - loss: 0.2341 - accuracy: 0.9784\n",
      "Epoch 74/200\n",
      "288/288 [==============================] - 0s 649us/step - loss: 0.2333 - accuracy: 0.9791\n",
      "Epoch 75/200\n",
      "288/288 [==============================] - 0s 653us/step - loss: 0.2327 - accuracy: 0.9791\n",
      "Epoch 76/200\n",
      "288/288 [==============================] - 0s 650us/step - loss: 0.2319 - accuracy: 0.9798\n",
      "Epoch 77/200\n",
      "288/288 [==============================] - 0s 645us/step - loss: 0.2312 - accuracy: 0.9798\n",
      "Epoch 78/200\n",
      "288/288 [==============================] - 0s 648us/step - loss: 0.2304 - accuracy: 0.9805\n",
      "Epoch 79/200\n",
      "288/288 [==============================] - 0s 650us/step - loss: 0.2298 - accuracy: 0.9812\n",
      "Epoch 80/200\n",
      "288/288 [==============================] - 0s 669us/step - loss: 0.2291 - accuracy: 0.9812\n",
      "Epoch 81/200\n",
      "288/288 [==============================] - 0s 664us/step - loss: 0.2284 - accuracy: 0.9819\n",
      "Epoch 82/200\n",
      "288/288 [==============================] - 0s 644us/step - loss: 0.2278 - accuracy: 0.9826\n",
      "Epoch 83/200\n",
      "288/288 [==============================] - 0s 647us/step - loss: 0.2271 - accuracy: 0.9819\n",
      "Epoch 84/200\n",
      "288/288 [==============================] - 0s 650us/step - loss: 0.2265 - accuracy: 0.9819\n",
      "Epoch 85/200\n",
      "288/288 [==============================] - 0s 651us/step - loss: 0.2258 - accuracy: 0.9819\n",
      "Epoch 86/200\n",
      "288/288 [==============================] - 0s 651us/step - loss: 0.2253 - accuracy: 0.9819\n",
      "Epoch 87/200\n",
      "288/288 [==============================] - 0s 657us/step - loss: 0.2247 - accuracy: 0.9826\n",
      "Epoch 88/200\n",
      "288/288 [==============================] - 0s 657us/step - loss: 0.2241 - accuracy: 0.9819\n",
      "Epoch 89/200\n",
      "288/288 [==============================] - 0s 653us/step - loss: 0.2235 - accuracy: 0.9826\n",
      "Epoch 90/200\n",
      "288/288 [==============================] - 0s 643us/step - loss: 0.2229 - accuracy: 0.9819\n",
      "Epoch 91/200\n",
      "288/288 [==============================] - 0s 658us/step - loss: 0.2224 - accuracy: 0.9833\n",
      "Epoch 92/200\n",
      "288/288 [==============================] - 0s 650us/step - loss: 0.2218 - accuracy: 0.9840\n",
      "Epoch 93/200\n",
      "288/288 [==============================] - 0s 645us/step - loss: 0.2212 - accuracy: 0.9840\n",
      "Epoch 94/200\n",
      "288/288 [==============================] - 0s 649us/step - loss: 0.2207 - accuracy: 0.9847\n",
      "Epoch 95/200\n",
      "288/288 [==============================] - 0s 641us/step - loss: 0.2202 - accuracy: 0.9847\n",
      "Epoch 96/200\n",
      "288/288 [==============================] - 0s 655us/step - loss: 0.2197 - accuracy: 0.9847\n",
      "Epoch 97/200\n",
      "288/288 [==============================] - 0s 650us/step - loss: 0.2192 - accuracy: 0.9861\n",
      "Epoch 98/200\n",
      "288/288 [==============================] - 0s 675us/step - loss: 0.2187 - accuracy: 0.9854\n",
      "Epoch 99/200\n",
      "288/288 [==============================] - 0s 727us/step - loss: 0.2182 - accuracy: 0.9861\n",
      "Epoch 100/200\n",
      "288/288 [==============================] - 0s 710us/step - loss: 0.2177 - accuracy: 0.9868\n",
      "Epoch 101/200\n",
      "288/288 [==============================] - 0s 692us/step - loss: 0.2172 - accuracy: 0.9875\n",
      "Epoch 102/200\n",
      "288/288 [==============================] - 0s 655us/step - loss: 0.2167 - accuracy: 0.9889\n",
      "Epoch 103/200\n",
      "288/288 [==============================] - 0s 666us/step - loss: 0.2163 - accuracy: 0.9889\n",
      "Epoch 104/200\n",
      "288/288 [==============================] - 0s 719us/step - loss: 0.2158 - accuracy: 0.9889\n",
      "Epoch 105/200\n",
      "288/288 [==============================] - 0s 696us/step - loss: 0.2151 - accuracy: 0.9889\n",
      "Epoch 106/200\n",
      "288/288 [==============================] - 0s 680us/step - loss: 0.2149 - accuracy: 0.9896\n",
      "Epoch 107/200\n",
      "288/288 [==============================] - 0s 657us/step - loss: 0.2143 - accuracy: 0.9889\n",
      "Epoch 108/200\n",
      "288/288 [==============================] - 0s 669us/step - loss: 0.2140 - accuracy: 0.9896\n",
      "Epoch 109/200\n",
      "288/288 [==============================] - 0s 700us/step - loss: 0.2135 - accuracy: 0.9896\n",
      "Epoch 110/200\n",
      "288/288 [==============================] - 0s 670us/step - loss: 0.2131 - accuracy: 0.9903\n",
      "Epoch 111/200\n",
      "288/288 [==============================] - 0s 670us/step - loss: 0.2127 - accuracy: 0.9896\n",
      "Epoch 112/200\n",
      "288/288 [==============================] - 0s 671us/step - loss: 0.2123 - accuracy: 0.9910\n",
      "Epoch 113/200\n",
      "288/288 [==============================] - 0s 662us/step - loss: 0.2118 - accuracy: 0.9910\n",
      "Epoch 114/200\n",
      "288/288 [==============================] - 0s 657us/step - loss: 0.2114 - accuracy: 0.9910\n",
      "Epoch 115/200\n",
      "288/288 [==============================] - 0s 657us/step - loss: 0.2110 - accuracy: 0.9910\n",
      "Epoch 116/200\n",
      "288/288 [==============================] - 0s 679us/step - loss: 0.2106 - accuracy: 0.9910\n",
      "Epoch 117/200\n",
      "288/288 [==============================] - 0s 686us/step - loss: 0.2102 - accuracy: 0.9910\n",
      "Epoch 118/200\n",
      "288/288 [==============================] - 0s 688us/step - loss: 0.2098 - accuracy: 0.9910\n",
      "Epoch 119/200\n",
      "288/288 [==============================] - 0s 665us/step - loss: 0.2094 - accuracy: 0.9910\n",
      "Epoch 120/200\n",
      "288/288 [==============================] - 0s 649us/step - loss: 0.2090 - accuracy: 0.9910\n",
      "Epoch 121/200\n",
      "288/288 [==============================] - 0s 649us/step - loss: 0.2086 - accuracy: 0.9910\n",
      "Epoch 122/200\n",
      "288/288 [==============================] - 0s 662us/step - loss: 0.2082 - accuracy: 0.9916\n",
      "Epoch 123/200\n",
      "288/288 [==============================] - 0s 654us/step - loss: 0.2079 - accuracy: 0.9916\n",
      "Epoch 124/200\n",
      "288/288 [==============================] - 0s 664us/step - loss: 0.2075 - accuracy: 0.9923\n",
      "Epoch 125/200\n",
      "288/288 [==============================] - 0s 660us/step - loss: 0.2071 - accuracy: 0.9923\n",
      "Epoch 126/200\n",
      "288/288 [==============================] - 0s 660us/step - loss: 0.2067 - accuracy: 0.9923\n",
      "Epoch 127/200\n",
      "288/288 [==============================] - 0s 711us/step - loss: 0.2064 - accuracy: 0.9916\n",
      "Epoch 128/200\n",
      "288/288 [==============================] - 0s 716us/step - loss: 0.2060 - accuracy: 0.9923\n",
      "Epoch 129/200\n",
      "288/288 [==============================] - 0s 678us/step - loss: 0.2056 - accuracy: 0.9923\n",
      "Epoch 130/200\n",
      "288/288 [==============================] - 0s 678us/step - loss: 0.2053 - accuracy: 0.9923\n",
      "Epoch 131/200\n",
      "288/288 [==============================] - 0s 664us/step - loss: 0.2049 - accuracy: 0.9923\n",
      "Epoch 132/200\n",
      "288/288 [==============================] - 0s 651us/step - loss: 0.2046 - accuracy: 0.9923\n",
      "Epoch 133/200\n",
      "288/288 [==============================] - 0s 688us/step - loss: 0.2042 - accuracy: 0.9923\n",
      "Epoch 134/200\n",
      "288/288 [==============================] - 0s 691us/step - loss: 0.2039 - accuracy: 0.9923\n",
      "Epoch 135/200\n",
      "288/288 [==============================] - 0s 667us/step - loss: 0.2035 - accuracy: 0.9923\n",
      "Epoch 136/200\n",
      "288/288 [==============================] - 0s 658us/step - loss: 0.2032 - accuracy: 0.9923\n",
      "Epoch 137/200\n",
      "288/288 [==============================] - 0s 664us/step - loss: 0.2029 - accuracy: 0.9923\n",
      "Epoch 138/200\n",
      "288/288 [==============================] - 0s 703us/step - loss: 0.2023 - accuracy: 0.9923\n",
      "Epoch 139/200\n",
      "288/288 [==============================] - 0s 674us/step - loss: 0.2022 - accuracy: 0.9930\n",
      "Epoch 140/200\n",
      "288/288 [==============================] - 0s 663us/step - loss: 0.2018 - accuracy: 0.9930\n",
      "Epoch 141/200\n",
      "288/288 [==============================] - 0s 661us/step - loss: 0.2016 - accuracy: 0.9930\n",
      "Epoch 142/200\n",
      "288/288 [==============================] - 0s 658us/step - loss: 0.2012 - accuracy: 0.9930\n",
      "Epoch 143/200\n",
      "288/288 [==============================] - 0s 710us/step - loss: 0.2009 - accuracy: 0.9930\n",
      "Epoch 144/200\n",
      "288/288 [==============================] - 0s 680us/step - loss: 0.2006 - accuracy: 0.9930\n",
      "Epoch 145/200\n",
      "288/288 [==============================] - 0s 682us/step - loss: 0.2003 - accuracy: 0.9930\n",
      "Epoch 146/200\n",
      "288/288 [==============================] - 0s 644us/step - loss: 0.1999 - accuracy: 0.9930\n",
      "Epoch 147/200\n",
      "288/288 [==============================] - 0s 662us/step - loss: 0.1996 - accuracy: 0.9930\n",
      "Epoch 148/200\n",
      "288/288 [==============================] - 0s 640us/step - loss: 0.1993 - accuracy: 0.9930\n",
      "Epoch 149/200\n",
      "288/288 [==============================] - 0s 698us/step - loss: 0.1990 - accuracy: 0.9930\n",
      "Epoch 150/200\n",
      "288/288 [==============================] - 0s 707us/step - loss: 0.1987 - accuracy: 0.9930\n",
      "Epoch 151/200\n",
      "288/288 [==============================] - 0s 679us/step - loss: 0.1984 - accuracy: 0.9930\n",
      "Epoch 152/200\n",
      "288/288 [==============================] - 0s 662us/step - loss: 0.1981 - accuracy: 0.9930\n",
      "Epoch 153/200\n",
      "288/288 [==============================] - 0s 653us/step - loss: 0.1978 - accuracy: 0.9930\n",
      "Epoch 154/200\n",
      "288/288 [==============================] - 0s 661us/step - loss: 0.1975 - accuracy: 0.9930\n",
      "Epoch 155/200\n",
      "288/288 [==============================] - 0s 683us/step - loss: 0.1972 - accuracy: 0.9930\n",
      "Epoch 156/200\n",
      "288/288 [==============================] - 0s 697us/step - loss: 0.1969 - accuracy: 0.9930\n",
      "Epoch 157/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288/288 [==============================] - 0s 669us/step - loss: 0.1966 - accuracy: 0.9930\n",
      "Epoch 158/200\n",
      "288/288 [==============================] - 0s 649us/step - loss: 0.1963 - accuracy: 0.9930\n",
      "Epoch 159/200\n",
      "288/288 [==============================] - 0s 643us/step - loss: 0.1960 - accuracy: 0.9930\n",
      "Epoch 160/200\n",
      "288/288 [==============================] - 0s 676us/step - loss: 0.1957 - accuracy: 0.9930\n",
      "Epoch 161/200\n",
      "288/288 [==============================] - 0s 710us/step - loss: 0.1954 - accuracy: 0.9930\n",
      "Epoch 162/200\n",
      "288/288 [==============================] - 0s 671us/step - loss: 0.1951 - accuracy: 0.9930\n",
      "Epoch 163/200\n",
      "288/288 [==============================] - 0s 659us/step - loss: 0.1949 - accuracy: 0.9930\n",
      "Epoch 164/200\n",
      "288/288 [==============================] - 0s 650us/step - loss: 0.1945 - accuracy: 0.9930\n",
      "Epoch 165/200\n",
      "288/288 [==============================] - 0s 648us/step - loss: 0.1943 - accuracy: 0.9930\n",
      "Epoch 166/200\n",
      "288/288 [==============================] - 0s 667us/step - loss: 0.1940 - accuracy: 0.9930\n",
      "Epoch 167/200\n",
      "288/288 [==============================] - 0s 658us/step - loss: 0.1937 - accuracy: 0.9930\n",
      "Epoch 168/200\n",
      "288/288 [==============================] - 0s 656us/step - loss: 0.1935 - accuracy: 0.9930\n",
      "Epoch 169/200\n",
      "288/288 [==============================] - 0s 654us/step - loss: 0.1932 - accuracy: 0.9930\n",
      "Epoch 170/200\n",
      "288/288 [==============================] - 0s 647us/step - loss: 0.1929 - accuracy: 0.9930\n",
      "Epoch 171/200\n",
      "288/288 [==============================] - 0s 654us/step - loss: 0.1926 - accuracy: 0.9930\n",
      "Epoch 172/200\n",
      "288/288 [==============================] - 0s 649us/step - loss: 0.1924 - accuracy: 0.9930\n",
      "Epoch 173/200\n",
      "288/288 [==============================] - 0s 702us/step - loss: 0.1921 - accuracy: 0.9930\n",
      "Epoch 174/200\n",
      "288/288 [==============================] - 0s 704us/step - loss: 0.1918 - accuracy: 0.9930\n",
      "Epoch 175/200\n",
      "288/288 [==============================] - 0s 686us/step - loss: 0.1915 - accuracy: 0.9930\n",
      "Epoch 176/200\n",
      "288/288 [==============================] - 0s 679us/step - loss: 0.1913 - accuracy: 0.9930\n",
      "Epoch 177/200\n",
      "288/288 [==============================] - 0s 669us/step - loss: 0.1910 - accuracy: 0.9930\n",
      "Epoch 178/200\n",
      "288/288 [==============================] - 0s 722us/step - loss: 0.1907 - accuracy: 0.9930\n",
      "Epoch 179/200\n",
      "288/288 [==============================] - 0s 754us/step - loss: 0.1905 - accuracy: 0.9930\n",
      "Epoch 180/200\n",
      "288/288 [==============================] - 0s 747us/step - loss: 0.1902 - accuracy: 0.9930\n",
      "Epoch 181/200\n",
      "288/288 [==============================] - 0s 775us/step - loss: 0.1899 - accuracy: 0.9930\n",
      "Epoch 182/200\n",
      "288/288 [==============================] - 0s 799us/step - loss: 0.1897 - accuracy: 0.9930\n",
      "Epoch 183/200\n",
      "288/288 [==============================] - 0s 807us/step - loss: 0.1894 - accuracy: 0.9930\n",
      "Epoch 184/200\n",
      "288/288 [==============================] - 0s 779us/step - loss: 0.1891 - accuracy: 0.9930\n",
      "Epoch 185/200\n",
      "288/288 [==============================] - 0s 774us/step - loss: 0.1889 - accuracy: 0.9930\n",
      "Epoch 186/200\n",
      "288/288 [==============================] - 0s 813us/step - loss: 0.1886 - accuracy: 0.9937\n",
      "Epoch 187/200\n",
      "288/288 [==============================] - 0s 764us/step - loss: 0.1884 - accuracy: 0.9930\n",
      "Epoch 188/200\n",
      "288/288 [==============================] - 0s 757us/step - loss: 0.1881 - accuracy: 0.9930\n",
      "Epoch 189/200\n",
      "288/288 [==============================] - 0s 795us/step - loss: 0.1879 - accuracy: 0.9937\n",
      "Epoch 190/200\n",
      "288/288 [==============================] - 0s 820us/step - loss: 0.1876 - accuracy: 0.9944\n",
      "Epoch 191/200\n",
      "288/288 [==============================] - 0s 779us/step - loss: 0.1873 - accuracy: 0.9937\n",
      "Epoch 192/200\n",
      "288/288 [==============================] - 0s 764us/step - loss: 0.1871 - accuracy: 0.9937\n",
      "Epoch 193/200\n",
      "288/288 [==============================] - 0s 779us/step - loss: 0.1868 - accuracy: 0.9944\n",
      "Epoch 194/200\n",
      "288/288 [==============================] - 0s 774us/step - loss: 0.1865 - accuracy: 0.9937\n",
      "Epoch 195/200\n",
      "288/288 [==============================] - 0s 816us/step - loss: 0.1863 - accuracy: 0.9930\n",
      "Epoch 196/200\n",
      "288/288 [==============================] - 0s 782us/step - loss: 0.1861 - accuracy: 0.9944\n",
      "Epoch 197/200\n",
      "288/288 [==============================] - 0s 756us/step - loss: 0.1858 - accuracy: 0.9951\n",
      "Epoch 198/200\n",
      "288/288 [==============================] - 0s 774us/step - loss: 0.1856 - accuracy: 0.9951\n",
      "Epoch 199/200\n",
      "288/288 [==============================] - 0s 819us/step - loss: 0.1853 - accuracy: 0.9951\n",
      "Epoch 200/200\n",
      "288/288 [==============================] - 0s 784us/step - loss: 0.1851 - accuracy: 0.9951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5396bfb160>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y2, epochs=200, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 775us/step\n"
     ]
    }
   ],
   "source": [
    "y_hat = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.3701512e-01, 5.1145523e-04, 2.3112925e-02, ..., 1.2179433e-03,\n",
       "        1.2640504e-03, 1.0598480e-02],\n",
       "       [5.7754079e-03, 6.7761806e-03, 7.8323421e-05, ..., 4.2409855e-03,\n",
       "        1.7385153e-03, 1.2766531e-03],\n",
       "       [4.0765796e-04, 4.9734337e-04, 2.8688072e-03, ..., 9.6815318e-01,\n",
       "        1.3293507e-02, 2.2244384e-03],\n",
       "       ...,\n",
       "       [1.3364435e-02, 2.4724612e-03, 4.0367144e-04, ..., 1.0516499e-03,\n",
       "        9.1743475e-04, 4.3298313e-04],\n",
       "       [2.5433939e-04, 1.1203498e-04, 1.8200411e-04, ..., 9.9295181e-01,\n",
       "        5.5053848e-04, 1.7077372e-03],\n",
       "       [5.3137168e-03, 1.4720210e-02, 6.4075756e-04, ..., 3.7032549e-04,\n",
       "        1.5527740e-02, 2.2641692e-04]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 4, 7, 1, 5, 6, 7, 6, 4, 4, 6, 1, 2, 0, 2, 9, 9, 8, 7, 0, 9, 8,\n",
       "        6, 8, 4, 5, 6, 6, 1, 3, 7, 3, 1, 7, 8, 6, 7, 0, 7, 5, 1, 4, 4, 9,\n",
       "        4, 5, 5, 7, 1, 2, 3, 6, 1, 0, 4, 8, 1, 9, 2, 7, 4, 4, 7, 4, 2, 8,\n",
       "        1, 1, 4, 7, 1, 9, 1, 2, 9, 2, 2, 9, 0, 7, 1, 4, 4, 4, 2, 6, 5, 8,\n",
       "        5, 5, 1, 9, 9, 5, 2, 4, 0, 8, 9, 1, 7, 8, 0, 4, 4, 6, 8, 2, 8, 8,\n",
       "        1, 5, 3, 3, 2, 0, 4, 3, 8, 7, 3, 4, 1, 5, 3, 9, 9, 1, 7, 6, 5, 9,\n",
       "        9, 2, 7, 3, 5, 0, 0, 3, 2, 2, 1, 7, 4, 1, 7, 2, 8, 1, 5, 1, 8, 1,\n",
       "        2, 5, 6, 1, 7, 6, 8, 5, 7, 0, 9, 8, 0, 3, 1, 6, 5, 2, 8, 3, 1, 2,\n",
       "        1, 2, 8, 7, 4, 2, 0, 5, 5, 3, 3, 4, 0, 5, 5, 9, 0, 3, 8, 7, 6, 4,\n",
       "        3, 2, 7, 6, 0, 1, 3, 4, 6, 7, 6, 7, 7, 7, 5, 7, 1, 6, 8, 4, 4, 1,\n",
       "        9, 0, 7, 0, 5, 8, 1, 0, 0, 3, 7, 9, 2, 1, 1, 5, 3, 7, 2, 5, 0, 6,\n",
       "        2, 9, 9, 1, 5, 7, 5, 9, 5, 0, 2, 7, 6, 7, 9, 2, 2, 2, 1, 3, 5, 5,\n",
       "        7, 4, 3, 0, 2, 7, 1, 0, 1, 9, 1, 0, 5, 7, 1, 4, 2, 0, 4, 4, 7, 5,\n",
       "        6, 7, 1, 5, 6, 2, 2, 3, 9, 1, 2, 4, 5, 5, 9, 3, 3, 3, 4, 7, 5, 9,\n",
       "        7, 7, 6, 8, 3, 3, 6, 4, 8, 5, 2, 7, 1, 0, 5, 0, 6, 2, 2, 0, 2, 4,\n",
       "        3, 4, 0, 6, 8, 9, 6, 0, 0, 9, 3, 1, 8, 9, 3, 2, 5, 6, 3, 5, 1, 9,\n",
       "        0, 2, 5, 2, 2, 4, 7, 6]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = [np.argmax(y) for y in y_hat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 7,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 9,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 8,\n",
       " 1,\n",
       " 9,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 0,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 5,\n",
       " 8,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 2,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 8,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 7,\n",
       " 3,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 5,\n",
       " 7,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 8,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 9,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 5,\n",
       " 5,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 6,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 8,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 9,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 7,\n",
       " 9,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 5,\n",
       " 7,\n",
       " 5,\n",
       " 9,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 7,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 5,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 8,\n",
       " 5,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 8,\n",
       " 9,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 3,\n",
       " 1,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 9,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 6]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[33,  0,  1,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 43,  0,  1,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0, 41,  1,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  1, 29,  0,  1,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0, 36,  0,  0,  0,  1,  0],\n",
       "       [ 0,  0,  0,  0,  0, 40,  0,  0,  0,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0, 30,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 44,  0,  0],\n",
       "       [ 0,  2,  1,  0,  0,  0,  1,  0, 22,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  1, 30]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_y.reshape(-1), y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.        , 0.95555556, 0.93181818, 0.93548387, 1.        ,\n",
       "        0.97560976, 0.96774194, 1.        , 0.91666667, 0.96774194]),\n",
       " array([0.97058824, 0.97727273, 0.97619048, 0.93548387, 0.97297297,\n",
       "        0.97560976, 1.        , 1.        , 0.84615385, 0.96774194]),\n",
       " array([0.98507463, 0.96629213, 0.95348837, 0.93548387, 0.98630137,\n",
       "        0.97560976, 0.98360656, 1.        , 0.88      , 0.96774194]),\n",
       " array([34, 44, 42, 31, 37, 41, 30, 44, 26, 31]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(test_y.reshape(-1), y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_y.reshape(-1), y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,122\n",
      "Trainable params: 26,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь сверточные сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Conv1D(32, 3, activation='relu'))\n",
    "model.add(layers.Conv1D(32, 3, activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.compile(keras.optimizers.Adam(learning_rate=0.001), keras.losses.MeanSquaredError(reduction='sum'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x3 = train_x.reshape(-1, 64, 1)\n",
    "train_y3 = train_y2.reshape(-1, 10, 1)\n",
    "test_x3 = test_x.reshape(-1, 64, 1)\n",
    "test_y3 = test_y2.reshape(-1, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 1.2130\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.3163\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.1838\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.1478\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.1068\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0744\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0512\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0352\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0258\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0239\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0335\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0378\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0264\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0385\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0476\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0578\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0343\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0231\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0145\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f537230fbe0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x3, train_y3, epochs=20)#, validation_data=(test_x3, test_y3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_hat = model.predict(test_x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = [np.argmax(y) for y in y_hat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[34,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 39,  4,  0,  1,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0, 42,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  1, 30,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0, 36,  0,  0,  0,  0,  1],\n",
       "       [ 0,  0,  0,  0,  0, 40,  0,  0,  0,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0, 30,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 44,  0,  0],\n",
       "       [ 0,  2,  2,  0,  0,  0,  0,  0, 22,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 31]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_y.reshape(-1), y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.        , 0.95121951, 0.85714286, 1.        , 0.97297297,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.93939394]),\n",
       " array([1.        , 0.88636364, 1.        , 0.96774194, 0.97297297,\n",
       "        0.97560976, 1.        , 1.        , 0.84615385, 1.        ]),\n",
       " array([1.        , 0.91764706, 0.92307692, 0.98360656, 0.97297297,\n",
       "        0.98765432, 1.        , 1.        , 0.91666667, 0.96875   ]),\n",
       " array([34, 44, 42, 31, 37, 41, 30, 44, 26, 31]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(test_y.reshape(-1), y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_y.reshape(-1), y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 62, 32)            128       \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 60, 32)            3104      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1920)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                19210     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,442\n",
      "Trainable params: 22,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Bidirectional(layers.LSTM(64)))\n",
    "model.add(layers.Dropout(0.1))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.compile(keras.optimizers.Adam(learning_rate=0.001, clipnorm=1.), \n",
    "               keras.losses.MeanSquaredError(reduction='sum'),\n",
    "               metrics=[keras.metrics.Precision()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-09 16:26:37.322124: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-09 16:26:37.323320: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-09 16:26:37.324054: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-09 16:26:37.400480: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-06-09 16:26:37.426406: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-09 16:26:37.427196: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-09 16:26:37.427858: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-09 16:26:37.544196: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-09 16:26:37.545303: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-09 16:26:37.546011: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-09 16:26:37.625850: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-06-09 16:26:37.655220: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-09 16:26:37.656120: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-09 16:26:37.656870: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-09 16:26:37.919624: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-06-09 16:26:38.177906: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-09 16:26:38.179054: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-09 16:26:38.179852: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-09 16:26:38.259706: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-06-09 16:26:38.288644: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-09 16:26:38.289605: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-09 16:26:38.290527: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-09 16:26:38.563242: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 2s 13ms/step - loss: 2.7746 - precision_1: 0.0000e+00\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 2.1543 - precision_1: 0.8732\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 1.5740 - precision_1: 0.8823\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 1.2627 - precision_1: 0.8709\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 1.0504 - precision_1: 0.8828\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 0.8828 - precision_1: 0.8918\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 0.7679 - precision_1: 0.9016\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 0.6535 - precision_1: 0.9237\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 0.5683 - precision_1: 0.9147\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 0.5334 - precision_1: 0.9235\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 0.4789 - precision_1: 0.9398\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 0.4728 - precision_1: 0.9313\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 0.4533 - precision_1: 0.9284\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 0.3875 - precision_1: 0.9391\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 0.3577 - precision_1: 0.9474\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.2916 - precision_1: 0.9591\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.3056 - precision_1: 0.9521\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.2892 - precision_1: 0.9599\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.2643 - precision_1: 0.9655\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.2281 - precision_1: 0.9694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f536063e260>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x3, train_y3, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-09 16:26:52.152123: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-09 16:26:52.153703: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-09 16:26:52.154804: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-09 16:26:52.284655: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-06-09 16:26:52.327848: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-09 16:26:52.329048: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-09 16:26:52.330186: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "y_hat = model.predict(test_x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = [np.argmax(y) for y in y_hat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[34,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 44,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0, 39,  2,  0,  0,  1,  0,  0,  0],\n",
       "       [ 0,  0,  0, 30,  0,  1,  0,  0,  0,  0],\n",
       "       [ 0,  1,  0,  0, 36,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 37,  0,  3,  0,  1],\n",
       "       [ 0,  1,  1,  0,  0,  0, 28,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 44,  0,  0],\n",
       "       [ 1,  2,  0,  0,  0,  0,  1,  0, 21,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 31]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_y.reshape(-1), y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.97142857, 0.91666667, 0.975     , 0.9375    , 1.        ,\n",
       "        0.97368421, 0.93333333, 0.93617021, 1.        , 0.93939394]),\n",
       " array([1.        , 1.        , 0.92857143, 0.96774194, 0.97297297,\n",
       "        0.90243902, 0.93333333, 1.        , 0.80769231, 1.        ]),\n",
       " array([0.98550725, 0.95652174, 0.95121951, 0.95238095, 0.98630137,\n",
       "        0.93670886, 0.93333333, 0.96703297, 0.89361702, 0.96875   ]),\n",
       " array([34, 44, 42, 31, 37, 41, 30, 44, 26, 31]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(test_y.reshape(-1), y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9555555555555556"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_y.reshape(-1), y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_1 (Bidirectio  (None, 128)              33792     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35,082\n",
      "Trainable params: 35,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
